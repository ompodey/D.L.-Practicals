{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3753cd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\om podey\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7500 - loss: 0.6925 - val_accuracy: 1.0000 - val_loss: 0.6556\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6749 - val_accuracy: 1.0000 - val_loss: 0.6178\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6573 - val_accuracy: 1.0000 - val_loss: 0.5825\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6417 - val_accuracy: 1.0000 - val_loss: 0.5490\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6277 - val_accuracy: 1.0000 - val_loss: 0.5182\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.6156 - val_accuracy: 1.0000 - val_loss: 0.4882\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.6046 - val_accuracy: 1.0000 - val_loss: 0.4599\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.5950 - val_accuracy: 1.0000 - val_loss: 0.4333\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5869 - val_accuracy: 1.0000 - val_loss: 0.4088\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5802 - val_accuracy: 1.0000 - val_loss: 0.3864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.3864\n",
      "Test accuracy: 1.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Prediction: [[0.67982733]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'review': [\n",
    "        \"One of the other reviewers has mentioned that ...\",\n",
    "        \"A wonderful little production. <br /><br />The...\",\n",
    "        \"I thought this was a wonderful way to spend ti...\",\n",
    "        \"Basically there's a family where a little boy ...\",\n",
    "        \"Petter Mattei's 'Love in the Time of Money' is...\"\n",
    "    ],\n",
    "    'sentiment': ['positive', 'positive', 'positive', 'negative', 'positive']\n",
    "})\n",
    "\n",
    "# Label encoding for sentiment\n",
    "label_encoder = LabelEncoder()\n",
    "data['sentiment_encoded'] = label_encoder.fit_transform(data['sentiment'])\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data['review'], data['sentiment_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a tokenizer and fit it on the training data\n",
    "num_words = 10000  # Keeping the top 10,000 words\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=num_words)\n",
    "\n",
    "# Fit the tokenizer on the training data\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "# Convert text data to sequences of integers\n",
    "x_train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# Pad the sequences to a consistent length\n",
    "max_len = 500\n",
    "x_train_padded = keras.preprocessing.sequence.pad_sequences(x_train_sequences, maxlen=max_len)\n",
    "x_test_padded = keras.preprocessing.sequence.pad_sequences(x_test_sequences, maxlen=max_len)\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(input_dim=num_words, output_dim=16, input_length=max_len),  # Embedding layer\n",
    "    layers.GlobalAveragePooling1D(),  # Global average pooling\n",
    "    layers.Dense(16, activation='relu'),  # Dense hidden layer\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer, binary cross-entropy loss, and accuracy metric\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with validation data\n",
    "model.fit(x_train_padded, y_train, epochs=10, batch_size=512, validation_data=(x_test_padded, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test_padded, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# Example: Make predictions with the model\n",
    "# Create new sample data (must be tokenized and padded like the training data)\n",
    "new_review = [\"I really enjoyed the movie. It was fantastic!\"]  # Example text review\n",
    "new_review_sequences = tokenizer.texts_to_sequences(new_review)\n",
    "new_review_padded = keras.preprocessing.sequence.pad_sequences(new_review_sequences, maxlen=max_len)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(new_review_padded)\n",
    "\n",
    "# Display the prediction (a value close to 0 means negative, close to 1 means positive)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a202e634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
